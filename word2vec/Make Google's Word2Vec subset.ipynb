{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "1. Download Google Word2Vec pre-trined model (embeddings) [https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing]\n",
    "2. It is huge and contains tons of garbage. Thus, we retain only a small subset of the words used in the sample text.\n",
    "...\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def just_words(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf8\") as f:\n",
    "        txt = f.read() \n",
    "        exclude = set(string.punctuation)\n",
    "        #remove punctuation\n",
    "        txt = ''.join(ch for ch in txt if ch not in exclude)\n",
    "        #split into words\n",
    "        words = txt.split();\n",
    "        \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Make Google's Word2Vec subset\n",
    "### ACHTUNG!! we're about to load around 3.5GB\n",
    "\n",
    "Retain the words used in Potter text only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import string\n",
    "import collections\n",
    "import pickle\n",
    "\n",
    "###########\n",
    "# This takes some time\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "###########\n",
    "potter_words=just_words(\"potter.txt\");\n",
    "vocabulary_size=25000 #should be enough\n",
    "embeddings={}\n",
    "###########\n",
    "\n",
    "count = [['UNK', -1]]\n",
    "# only 25K of popular words\n",
    "count.extend(collections.Counter(potter_words).most_common(vocabulary_size - 1))\n",
    "\n",
    "for w in count:\n",
    "    word=w[0]\n",
    "    if word in model.vocab:\n",
    "        embeddings[word]=model[word]\n",
    "\n",
    "#save the subset as pickle\n",
    "with open(\"potter_embeddings.txt\", \"wb\") as small_embeddings_file:\n",
    "    pickle.dump(embeddings, small_embeddings_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### keep it clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "del model\n",
    "del count\n",
    "del embeddings\n",
    "del potter_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
